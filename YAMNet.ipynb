{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6776614e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\tensorflow_hub\\__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading YAMNet model...\n",
      "WARNING:tensorflow:From c:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_UserObject' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading YAMNet model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m yamnet_model = hub.load(\u001b[33m'\u001b[39m\u001b[33mhttps://tfhub.dev/google/yamnet/1\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m yamnet_classes = \u001b[43myamnet_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m.get_output_by_name(\u001b[33m'\u001b[39m\u001b[33mclass_scores\u001b[39m\u001b[33m'\u001b[39m).name\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Define your custom class labels and mapping to YAMNet classes (approximate)\u001b[39;00m\n\u001b[32m     16\u001b[39m custom_labels = [\n\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbicycle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMotorcycle\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcar\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpickup\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSUV\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPSV\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBuses\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mLight Trucks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMedium trucks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mHeavy trucks\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcar_horn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdrilling\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mengine_idling\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msiren\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m ]\n",
      "\u001b[31mAttributeError\u001b[39m: '_UserObject' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import resampy\n",
    "\n",
    "# Load YAMNet model\n",
    "print(\"Loading YAMNet model...\")\n",
    "yamnet_model = hub.load('https://tfhub.dev/google/yamnet/1')\n",
    "yamnet_classes = yamnet_model.graph.get_output_by_name('class_scores').name\n",
    "\n",
    "# Define your custom class labels and mapping to YAMNet classes (approximate)\n",
    "custom_labels = [\n",
    "    \"bicycle\", \"Motorcycle\", \"car\", \"pickup\", \"SUV\", \"PSV\", \"Buses\",\n",
    "    \"Light Trucks\", \"Medium trucks\", \"Heavy trucks\", \"car_horn\",\n",
    "    \"drilling\", \"engine_idling\", \"siren\"\n",
    "]\n",
    "class_id_map = {i: label for i, label in enumerate(custom_labels)}  # 0 to 13\n",
    "yamnet_to_custom = {\n",
    "    247: \"car_horn\",    # Car horn\n",
    "    295: \"siren\",       # Siren\n",
    "    149: \"engine_idling\",  # Engine (approximate)\n",
    "    256: \"Motorcycle\",  # Motorcycle\n",
    "    # Add more mappings if available, or use defaults for others\n",
    "}\n",
    "default_class_id = 0  # Default to \"bicycle\" if no match\n",
    "\n",
    "def predict_class(audio, sr):\n",
    "    \"\"\"Predict class label using YAMNet and map to custom labels.\"\"\"\n",
    "    # Resample to 16000 Hz (YAMNet's expected sample rate)\n",
    "    if sr != 16000:\n",
    "        audio = resampy.resample(audio, sr, 16000)\n",
    "        sr = 16000\n",
    "    \n",
    "    # Ensure audio is in the correct shape [samples, channels]\n",
    "    if len(audio.shape) == 1:\n",
    "        audio = np.expand_dims(audio, axis=1)\n",
    "    audio = audio.astype(np.float32)\n",
    "\n",
    "    # Get YAMNet scores\n",
    "    scores, embeddings, spectrogram = yamnet_model(audio)\n",
    "    predicted_class = np.argmax(scores, axis=1)[0]  # Top prediction\n",
    "    class_name = yamnet_to_custom.get(predicted_class, custom_labels[default_class_id])\n",
    "    class_id = custom_labels.index(class_name)\n",
    "    return class_name, class_id\n",
    "\n",
    "def split_audio_and_create_metadata(audio_dir, output_dir, class_labels, chunk_length=6, overlap=0):\n",
    "    \"\"\"\n",
    "    Split all WAV files into chunks, predict class labels with YAMNet, and create a single metadata file.\n",
    "    \n",
    "    Parameters:\n",
    "    - audio_dir: Directory containing WAV audio files.\n",
    "    - output_dir: Directory to save road folders, audio chunks, and metadata.\n",
    "    - class_labels: Dictionary mapping audio filenames to (class, classID) tuples, or path to a CSV.\n",
    "    - chunk_length: Length of each chunk in seconds (default: 6).\n",
    "    - overlap: Overlap between chunks in seconds (default: 0).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify audio_dir exists\n",
    "    if not os.path.exists(audio_dir):\n",
    "        print(f\"Error: audio_dir '{audio_dir}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Output directory created or exists: {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating output_dir '{output_dir}': {e}\")\n",
    "        return\n",
    "    \n",
    "    # Initialize metadata list\n",
    "    metadata = []\n",
    "    \n",
    "    # Handle class labels (optional override)\n",
    "    if isinstance(class_labels, str):\n",
    "        try:\n",
    "            label_df = pd.read_csv(class_labels)\n",
    "            class_labels = {row['filename']: (row['class'], row['classID']) for _, row in label_df.iterrows()}\n",
    "            print(f\"Loaded class labels from CSV: {class_labels}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading class_labels CSV '{class_labels}': {e}\")\n",
    "            return\n",
    "    \n",
    "    # Find all audio files in audio_dir\n",
    "    audio_files = [str(p) for p in Path(audio_dir).glob(\"*.wav\")]\n",
    "    print(f\"Found {len(audio_files)} WAV files in {audio_dir}: {audio_files}\")\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(\"No WAV files found. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Process each audio file\n",
    "    for audio_path in audio_files:\n",
    "        audio_filename = os.path.basename(audio_path)\n",
    "        print(f\"Processing file: {audio_filename}\")\n",
    "        \n",
    "        # Get class label and class id from dictionary (overridden by prediction)\n",
    "        class_label, class_id = class_labels.get(audio_filename, (\"unknown\", -1))\n",
    "        print(f\"Initial class_label: {class_label}, class_id: {class_id}\")\n",
    "        \n",
    "        # Generate fsID\n",
    "        fsID = audio_filename.split('-')[0] if '-' in audio_filename else audio_filename.split('.')[0]\n",
    "        print(f\"fsID: {fsID}\")\n",
    "        \n",
    "        # Define road name as the filename without extension\n",
    "        road_name = os.path.splitext(audio_filename)[0]\n",
    "        road_dir = os.path.join(output_dir, road_name)\n",
    "        try:\n",
    "            os.makedirs(road_dir, exist_ok=True)\n",
    "            print(f\"Created road directory: {road_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating road_dir '{road_dir}': {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Load audio file with soundfile\n",
    "        try:\n",
    "            audio, sr = sf.read(audio_path)\n",
    "            audio_duration = len(audio) / sr\n",
    "            print(f\"Loaded audio with soundfile: {audio_path}, duration: {audio_duration}s, sample rate: {sr}Hz\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading audio file '{audio_path}' with soundfile: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate number of samples per chunk\n",
    "        samples_per_chunk = int(chunk_length * sr)\n",
    "        step_size = int((chunk_length - overlap) * sr)\n",
    "        print(f\"Samples per chunk: {samples_per_chunk}, step size: {step_size}\")\n",
    "        \n",
    "        # Split audio into chunks\n",
    "        for i in range(0, len(audio) - samples_per_chunk + 1, step_size):\n",
    "            start_sample = i\n",
    "            end_sample = i + samples_per_chunk\n",
    "            \n",
    "            # Extract chunk\n",
    "            chunk = audio[start_sample:end_sample]\n",
    "            \n",
    "            # Define chunk filename\n",
    "            chunk_index = i // step_size\n",
    "            slice_file_name = f\"{fsID}-{class_id}-{chunk_index}.wav\"\n",
    "            chunk_path = os.path.join(road_dir, slice_file_name)\n",
    "            \n",
    "            # Save chunk as WAV file\n",
    "            try:\n",
    "                sf.write(chunk_path, chunk, sr)\n",
    "                print(f\"Saved chunk: {chunk_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving chunk '{chunk_path}': {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Predict class for this chunk\n",
    "            try:\n",
    "                predicted_class, predicted_id = predict_class(chunk, sr)\n",
    "                print(f\"Predicted class for {slice_file_name}: {predicted_class}, ID: {predicted_id}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error predicting class for '{chunk_path}': {e}\")\n",
    "                predicted_class, predicted_id = \"unknown\", -1\n",
    "            \n",
    "            # Calculate start and end times\n",
    "            start_time = start_sample / sr\n",
    "            end_time = end_sample / sr\n",
    "            \n",
    "            # Append to metadata with predicted values\n",
    "            metadata.append({\n",
    "                \"slice_file_name\": slice_file_name,\n",
    "                \"fsID\": fsID,\n",
    "                \"start\": start_time,\n",
    "                \"end\": end_time,\n",
    "                \"road\": road_name,\n",
    "                \"classID\": predicted_id,\n",
    "                \"class\": predicted_class\n",
    "            })\n",
    "            print(f\"Added metadata for chunk: {slice_file_name}\")\n",
    "        \n",
    "        # Handle the last chunk if audio length is not perfectly divisible\n",
    "        if len(audio) % step_size > 0:\n",
    "            start_sample = len(audio) - samples_per_chunk\n",
    "            if start_sample >= 0:\n",
    "                chunk = audio[start_sample:]\n",
    "                chunk_index = len(metadata)\n",
    "                slice_file_name = f\"{fsID}-{class_id}-{chunk_index}.wav\"\n",
    "                chunk_path = os.path.join(road_dir, slice_file_name)\n",
    "                \n",
    "                try:\n",
    "                    sf.write(chunk_path, chunk, sr)\n",
    "                    print(f\"Saved last chunk: {chunk_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error saving last chunk '{chunk_path}': {e}\")\n",
    "                    continue\n",
    "                \n",
    "                # Predict class for this chunk\n",
    "                try:\n",
    "                    predicted_class, predicted_id = predict_class(chunk, sr)\n",
    "                    print(f\"Predicted class for {slice_file_name}: {predicted_class}, ID: {predicted_id}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error predicting class for '{chunk_path}': {e}\")\n",
    "                    predicted_class, predicted_id = \"unknown\", -1\n",
    "                \n",
    "                start_time = start_sample / sr\n",
    "                end_time = len(audio) / sr\n",
    "                metadata.append({\n",
    "                    \"slice_file_name\": slice_file_name,\n",
    "                    \"fsID\": fsID,\n",
    "                    \"start\": start_time,\n",
    "                    \"end\": end_time,\n",
    "                    \"road\": road_name,\n",
    "                    \"classID\": predicted_id,\n",
    "                    \"class\": predicted_class\n",
    "                })\n",
    "                print(f\"Added metadata for last chunk: {slice_file_name}\")\n",
    "    \n",
    "    # Create metadata DataFrame and save to CSV\n",
    "    if metadata:\n",
    "        metadata_df = pd.DataFrame(metadata)\n",
    "        metadata_path = os.path.join(output_dir, \"metadata.csv\")\n",
    "        try:\n",
    "            metadata_df.to_csv(metadata_path, index=False)\n",
    "            print(f\"Metadata saved to {metadata_path}\")\n",
    "            print(f\"Created {len(metadata)} chunks from {len(audio_files)} files.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving metadata to '{metadata_path}': {e}\")\n",
    "    else:\n",
    "        print(\"No metadata to save. No chunks were created.\")\n",
    "\n",
    "# Example usage\n",
    "audio_dir = \"data/DATA\"  # Directory with WAV files\n",
    "output_dir = \"data/DATA/output_chunks\"  # Directory to save road folders, chunks, and metadata\n",
    "class_labels = {}  # Optional, overridden by predictions\n",
    "chunk_length = 6  # Chunk length in seconds\n",
    "overlap = 0       # Overlap in seconds\n",
    "\n",
    "split_audio_and_create_metadata(audio_dir, output_dir, class_labels, chunk_length, overlap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
