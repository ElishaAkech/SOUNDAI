{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07c740",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeoDataFrame' object has no attribute 'to_geojson'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_20036\\4243166542.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    226\u001b[39m gdf_edges[\u001b[33m'leq'\u001b[39m] = gdf_edges.geometry.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: get_nearest_noise_level(Point(x.coords[\u001b[32m0\u001b[39m]), gdf_noise))\n\u001b[32m    227\u001b[39m \n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Convert to GeoJSON\u001b[39;00m\n\u001b[32m    229\u001b[39m gdf_edges = gdf_edges[[\u001b[33m'geometry'\u001b[39m, \u001b[33m'leq'\u001b[39m, \u001b[33m'name'\u001b[39m]].dropna(subset=[\u001b[33m'leq'\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m geojson_data = gdf_edges.to_geojson()\n\u001b[32m    231\u001b[39m \n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# Save GeoJSON\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m open(\u001b[33m'nairobi_noise_data.geojson'\u001b[39m, \u001b[33m'w'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[32mc:\\Users\\USER\\Desktop\\SonusAI\\venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   6314\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m name \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m self._accessors\n\u001b[32m   6315\u001b[39m             \u001b[38;5;28;01mand\u001b[39;00m self._info_axis._can_hold_identifiers_and_holds_name(name)\n\u001b[32m   6316\u001b[39m         ):\n\u001b[32m   6317\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m self[name]\n\u001b[32m-> \u001b[39m\u001b[32m6318\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m object.__getattribute__(self, name)\n",
      "\u001b[31mAttributeError\u001b[39m: 'GeoDataFrame' object has no attribute 'to_geojson'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import osmnx as ox\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyproj import Transformer\n",
    "from shapely.geometry import Point\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define NoisePredictor class (from notebook)\n",
    "class NoisePredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NoisePredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 25)\n",
    "        self.fc2 = nn.Linear(25, 50)\n",
    "        self.fc3 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Load trained model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NoisePredictor(input_dim=7)\n",
    "model.load_state_dict(torch.load('MLP_noise_predictor_model.pth'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load sheets and process data (your provided code)\n",
    "file_path = 'data\\\\FINAL DATA.xlsx'  # Update to your actual path\n",
    "df_leq = pd.read_excel(file_path, sheet_name='Noise Leq Data')\n",
    "df_speed = pd.read_excel(file_path, sheet_name='SPEED')\n",
    "df_pcu = pd.read_excel(file_path, sheet_name='PCU')\n",
    "df_pcu_conv = pd.read_excel(file_path, sheet_name='PCU Conversion')  # For vehicle counts\n",
    "\n",
    "# Modified data processing to extract vehicle categories like the paper\n",
    "data = []\n",
    "places = df_leq['Place'].dropna().unique()\n",
    "hours = ['6-7AM', '7-8AM', '8-9AM', '9-10AM', '10-11AM', '11-12PM', '12-1PM', '1-2PM', '2-3PM', '3-4PM', '4-5PM', '5-6PM']\n",
    "\n",
    "lanes_dict = {\n",
    "    'Around Arya School': 2,  # Ngara Arya\n",
    "    'Around Baba Dogo Rd': 2,\n",
    "    'Around Junction Mall': 4,\n",
    "    'Around Langata Hospital': 4,\n",
    "    'Around MMU': 4,\n",
    "    'BBS Eastleigh': 4,\n",
    "    'Bee Centre': 2,\n",
    "    'Close to Uhuru Park': 2,\n",
    "    'Davis&Shirtliff Kangundo Rd': 2,\n",
    "    'ICD Road': 4,\n",
    "    'Imaara Mall': 4,\n",
    "    'Jevanjee': 2,\n",
    "    'Jogoo Road': 4,\n",
    "    'Kangemi': 4,\n",
    "    'Karen C School': 2,\n",
    "    'Kawangware': 2,\n",
    "    'KCB Utawala Eastern Bypass': 4,\n",
    "    'KFC Embakasi': 4,\n",
    "    'Kiambu Road': 2,\n",
    "    'Kiambu Road 2': 2,\n",
    "    'Kinoo': 2,\n",
    "    'Langata Link Road': 4,\n",
    "    'Likoni Road': 4,\n",
    "    'Makongeni Shopping Centre Ruai': 2,\n",
    "    'Ngong Road': 4,\n",
    "    'Northern Bypass': 2,\n",
    "    'Nyayo Langata': 4,\n",
    "    'Ola Energy Waiyaki Way': 8,\n",
    "    'Opp. KU Hospital': 2,\n",
    "    'Quality Meat Packers': 2,\n",
    "    'Raila Odinga Road Next to Total': 4,\n",
    "    'Ruaka': 2,\n",
    "    'Runda': 2,\n",
    "    'Southern Bypass 1': 4,\n",
    "    'Southern Bypass 2': 4,\n",
    "    'Thika Road 1': 8,\n",
    "    'Thika Road 2': 8,\n",
    "    'Thika Road (Pangani)': 8,\n",
    "    'Thome': 2,\n",
    "    'Total Energies Outering': 8,\n",
    "    'Winners Chapel (Likoni Road)': 4,\n",
    "    'Junction Mall': 4,\n",
    "    'Arya (Ngara)': 2,\n",
    "    'Around Baba Dogo Road': 2\n",
    "}\n",
    "\n",
    "# Coordinates from Coordinates.xlsx (hardcoded from provided document)\n",
    "coords_dict = {\n",
    "    'UHURU PARK': (256896.83, 9857588.15),\n",
    "    'IMAARA MALL': (264136.81, 9853108.54),\n",
    "    'KIAMBU ROAD': (259705.6, 9864042.77),\n",
    "    'LANGATA LINK ROAD': (253374.75, 9853775.07),\n",
    "    'JEVANJEE': (257452.84, 9858326.03),\n",
    "    'KFC EMBAKASI': (268248.56, 9854218.08),\n",
    "    'RUNDA': (258096.36, 9865454.82),\n",
    "    'RAILA ODINGA ROAD NEXT TO TOTAL': (256590.06, 9854730.41),\n",
    "    'ARYA(NGARA)': (257947.14, 9858910.23),\n",
    "    'KCB UTAWALA EASTERN BYPASS': (272667.35, 9857939.17),\n",
    "    'RUAKA': (258094.93, 9867236.88),\n",
    "    'NYAYO LANGATA': (257702.58, 9855591.69),\n",
    "    'OLA ENERGY WAIYAKI WAY': (252935.73, 9860718.79),\n",
    "    'MAKONGENI SHOPPING CENTRE RUAI': (280644.38, 9858744.19),\n",
    "    'KIAMBU ROAD 2': (258775.95, 9866407.85),\n",
    "    'LIKONI ROAD': (259340.9, 9856361.23),\n",
    "    'KANGEMI': (249008.64, 9860131.61),\n",
    "    'QUALITY MEAT PACKERS': (272942.89, 9861441.77),\n",
    "    'THOME': (263693.17, 9866165.94),\n",
    "    'WINNERS CHAPEL(LIKONI ROAD)': (260611.02, 9853750.71),\n",
    "    'KINOO': (243719.36, 9861018.07),\n",
    "    'DAVIS & SHIRTLIFF KANGUNDO ROAD': (268614.18, 9860885.34),\n",
    "    'NORTHERN BYPASS': (266227.84, 9867581.2),\n",
    "    'LANGATA HOSPITAL': (253993.82, 9853130.38),\n",
    "    'SOUTHERN BYPASS 1': (243042.87, 9856654.09),\n",
    "    'BEE CENTRE': (266390.05, 9858026.26),\n",
    "    'OPP. KU HOSPITAL': (267772.27, 9869917.36),\n",
    "    'MMU': (251958.55, 9846860.37),\n",
    "    'SOUTHERN BYPASS 2': (244992.07, 9855764.76),\n",
    "    'TOTAL ENERGIES OUTERING': (264131.37, 9859591.32),\n",
    "    'NORTHERN BYPASS 2': (268760.56, 9871638.6),\n",
    "    'KAREN C SCHOOL': (248613.98, 9851927.16),\n",
    "    'NGONG ROAD': (248517.89, 9855522.13),\n",
    "    'JOGOO ROAD': (263515.43, 9856549.12),\n",
    "    'THIKA ROAD 1': (270432.25, 9869181.99),\n",
    "    'JUNCTION MALL': (251145.89, 9856292.64),\n",
    "    'KAWANGWARE': (248423.11, 9857765.12),\n",
    "    'BBS MALL EASTLEIGH': (260390.54, 9858451.41),\n",
    "    'THIKA ROAD 2': (264838.81, 9864569.18),\n",
    "    'ICD ROAD': (261941.98, 9852338.53),\n",
    "    'THIKA ROAD(PANGANI)': (259152.23, 9860048.07),\n",
    "    'AROUND BABA DOGO ROAD': (263418.15, 9862017.95)\n",
    "}\n",
    "\n",
    "for i, place in enumerate(places):\n",
    "    leq_row = df_leq.iloc[i, 2:].values  # Leq per hour\n",
    "    speed_row = df_speed.iloc[i, 2:].values  # Speed per hour\n",
    "    pcu_row = df_pcu.iloc[i, 2:].values  # PCU per hour\n",
    "    \n",
    "    # Get vehicle categories from PCU Conversion\n",
    "    place_conv = df_pcu_conv[df_pcu_conv['Place'].str.strip().str.upper() == place.strip().upper()]\n",
    "    if not place_conv.empty:\n",
    "        conv_row = place_conv.iloc[0, 3:].values  # Start from 'Bicycle' column\n",
    "        vehicle_cols = df_pcu_conv.columns[3:]  # Columns from 'Bicycle' onward\n",
    "        \n",
    "        # Extract vehicle counts (handle missing columns with defaults)\n",
    "        motorcycles = conv_row[list(vehicle_cols).index('Motorcycles')] if 'Motorcycles' in vehicle_cols else 0\n",
    "        light_cols = ['Private car', 'Pickup', 'SUV']  # Define light vehicle categories\n",
    "        light_vehicles = sum(conv_row[list(vehicle_cols).index(col)] for col in light_cols if col in vehicle_cols)\n",
    "        medium_cols = ['Buses', 'Light trucks']  # Define medium vehicle categories\n",
    "        medium_vehicles = sum(conv_row[list(vehicle_cols).index(col)] for col in medium_cols if col in vehicle_cols)\n",
    "        heavy_cols = ['Medium trucks', 'Heavy trucks']  # Define heavy vehicle categories\n",
    "        heavy_vehicles = sum(conv_row[list(vehicle_cols).index(col)] for col in heavy_cols if col in vehicle_cols)\n",
    "        \n",
    "        # Convert NaN to 0\n",
    "        motorcycles = 0 if pd.isna(motorcycles) else motorcycles\n",
    "        light_vehicles = 0 if pd.isna(light_vehicles) else light_vehicles\n",
    "        medium_vehicles = 0 if pd.isna(medium_vehicles) else medium_vehicles\n",
    "        heavy_vehicles = 0 if pd.isna(heavy_vehicles) else heavy_vehicles\n",
    "    else:\n",
    "        motorcycles = light_vehicles = medium_vehicles = heavy_vehicles = 0\n",
    "    \n",
    "    lanes = lanes_dict.get(place, 2)\n",
    "    \n",
    "    # Get X, Y coordinates\n",
    "    x_coord, y_coord = coords_dict.get(place.strip().upper(), (None, None))\n",
    "    \n",
    "    # Process each hour\n",
    "    for h, hour in enumerate(hours):\n",
    "        if pd.notna(leq_row[h]) and pd.notna(speed_row[h]) and pd.notna(pcu_row[h]):\n",
    "            current_speed = speed_row[h]\n",
    "            \n",
    "            # Flow type based on speed (like paper's traffic condition)\n",
    "            if current_speed < 20:\n",
    "                flow_type = 0  # Congested\n",
    "            elif current_speed < 35:\n",
    "                flow_type = 1  # Periodic\n",
    "            else:\n",
    "                flow_type = 2  # Fluid\n",
    "            \n",
    "            data.append({\n",
    "                'place': place,\n",
    "                'motorcycles': motorcycles,\n",
    "                'light': light_vehicles,\n",
    "                'medium': medium_vehicles,\n",
    "                'heavy': heavy_vehicles,\n",
    "                'speed': current_speed,\n",
    "                'lanes': lanes,\n",
    "                'flow_type': flow_type,\n",
    "                'leq': leq_row[h],\n",
    "                'hour': hours[h],\n",
    "                'x': x_coord,\n",
    "                'y': y_coord\n",
    "            })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(subset=['x', 'y'])  # Drop rows without coordinates\n",
    "\n",
    "# Convert X, Y (UTM Zone 37S) to latitude, longitude (EPSG:4326)\n",
    "transformer = Transformer.from_crs(\"EPSG:32737\", \"EPSG:4326\", always_xy=True)  # UTM Zone 37S to WGS84\n",
    "df['longitude'], df['latitude'] = zip(*df.apply(lambda row: transformer.transform(row['x'], row['y']), axis=1))\n",
    "\n",
    "# Predict Leq\n",
    "features = ['motorcycles', 'light', 'medium', 'heavy', 'speed', 'lanes', 'flow_type']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df[features].values)\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "with torch.no_grad():\n",
    "    leq_preds = model(X_tensor).cpu().numpy().flatten()\n",
    "df['leq_pred'] = leq_preds\n",
    "\n",
    "# Get Nairobi road network\n",
    "G = ox.graph_from_place('Nairobi, Kenya', network_type='drive')\n",
    "gdf_nodes, gdf_edges = ox.graph_to_gdfs(G)\n",
    "\n",
    "# Assign Leq to roads by nearest noise point\n",
    "def get_nearest_noise_level(road_point, noise_gdf):\n",
    "    distances = noise_gdf.geometry.distance(road_point)\n",
    "    nearest_idx = distances.idxmin()\n",
    "    return noise_gdf.loc[nearest_idx, 'leq_pred']\n",
    "gdf_noise = gpd.GeoDataFrame(df, geometry=[Point(lon, lat) for lat, lon in zip(df['longitude'], df['latitude'])], crs=\"EPSG:4326\")\n",
    "gdf_edges['leq'] = gdf_edges.geometry.apply(lambda x: get_nearest_noise_level(Point(x.coords[0]), gdf_noise))\n",
    "\n",
    "# Convert to GeoJSON\n",
    "gdf_edges = gdf_edges[['geometry', 'leq', 'name']].dropna(subset=['leq'])\n",
    "geojson_data = gdf_edges.to_geojson()\n",
    "\n",
    "# Save GeoJSON\n",
    "with open('nairobi_noise_data.geojson', 'w') as f:\n",
    "    json.dump(json.loads(geojson_data), f)\n",
    "\n",
    "print(\"GeoJSON data saved as 'nairobi_noise_data.geojson'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
