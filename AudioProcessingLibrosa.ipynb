{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c763fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dde96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957d1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_file = \"data\\\\test\\\\segment_1.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(scale_file, rate = sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02fc57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale,sr = librosa.load(scale_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8f33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673af3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d41517",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = librosa.stft(scale)\n",
    "scale_ft = librosa.amplitude_to_db(np.abs(d), ref=np.max)\n",
    "scale_ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the transofrmed audio\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "img = librosa.display.specshow(scale_ft,\n",
    "                               x_axis='time', \n",
    "                               y_axis='log',ax=ax)\n",
    "ax.set_title(\"Spectogram example\", fontsize=20)\n",
    "fig.colorbar(img,ax=ax, format=f'%0.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539b42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_banks = librosa.filters.mel(n_fft=2048, sr=22050, n_mels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_banks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf32333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(filter_banks, sr=sr, x_axis=\"linear\")\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bafaa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram = librosa.feature.melspectrogram(y=scale, sr=sr, n_fft=2048, hop_length=512, n_mels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d908435",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mel_spectogram = librosa.power_to_db(mel_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b42d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mel_spectogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c303bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "librosa.display.specshow(log_mel_spectogram, x_axis = \"time\", y_axis=\"mel\", sr=sr)\n",
    "\n",
    "plt.colorbar(format=\"%+2.f\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the WAV file\n",
    "waveform, sample_rate = torchaudio.load('data/scale.wav')\n",
    "\n",
    "# Convert to mono if stereo (many models expect mono)\n",
    "if waveform.shape[0] == 2:  # Stereo\n",
    "    waveform = torch.mean(waveform, dim=0, keepdim=True)  # Average channels\n",
    "\n",
    "# Compute mel spectrogram with common parameters\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=sample_rate,\n",
    "    n_mels=128,  # Standard for audio classification\n",
    "    n_fft=1024,  # FFT window size\n",
    "    hop_length=512  # Hop size for time resolution\n",
    ")\n",
    "mel_spectrogram = mel_transform(waveform)\n",
    "\n",
    "# Convert to decibel scale for better visualization and sometimes model input\n",
    "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
    "mel_spectrogram_db = db_transform(mel_spectrogram)\n",
    "\n",
    "# Save as numerical data (e.g., for model input)\n",
    "mel_spectrogram_np = mel_spectrogram_db.squeeze().numpy()  # Remove channel dim if mono\n",
    "np.save('mel_spectrogram.npy', mel_spectrogram_np)\n",
    "\n",
    "# Alternatively, save as PyTorch tensor\n",
    "# torch.save(mel_spectrogram_db, 'mel_spectrogram.pt')\n",
    "\n",
    "# Save as image for visualization\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spectrogram_db.squeeze().numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title('Mel Spectrogram (dB)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mel_spectrogram.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "for filename in os.listdir('data/'):\n",
    "    if filename.endswith('.wav'):\n",
    "        waveform, sample_rate = torchaudio.load(os.path.join('data/', filename))\n",
    "        if waveform.shape[0] == 2:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        mel_spectrogram = mel_transform(waveform)\n",
    "        mel_spectrogram_db = db_transform(mel_spectrogram)\n",
    "        mel_spectrogram_np = mel_spectrogram_db.squeeze().numpy()\n",
    "        np.save(f'mel_spectrogram_{filename[:-4]}.npy', mel_spectrogram_np)\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.imshow(mel_spectrogram_db.squeeze().numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.title(f'Mel Spectrogram (dB) - {filename}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'mel_spectrogram_{filename[:-4]}.png')\n",
    "        plt.close()  # Close figure to avoid memory issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cc9888",
   "metadata": {},
   "source": [
    "Steps\n",
    "Load Audio: Use librosa.load to get the audio samples and sampling rate.\n",
    "Apply A-Weighting: Filter the audio to mimic human hearing perception.\n",
    "Compute Leq: Calculate the mean squared pressure and convert to dBA.\n",
    "Handle Output: Return or display the Leq value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b5fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "\n",
    "# File path\n",
    "audio_file = \"data\\\\noiseData\\\\Around Arya School(1°16_32_ S 36°49_29_ E).wav\"\n",
    "\n",
    "# Load audio\n",
    "y, sr = librosa.load(audio_file, sr=None)  # y: audio samples, sr: sampling rate\n",
    "\n",
    "# Apply A-weighting (approximation using librosa's perceptual weighting)\n",
    "# librosa doesn't have direct A-weighting, so we use a simplified approach\n",
    "# For precise A-weighting, you may need scipy or custom filters\n",
    "def apply_a_weighting(signal, sr):\n",
    "    # Approximate A-weighting by emphasizing 1-6 kHz (simplified for demonstration)\n",
    "    # For production, use scipy.signal or a dedicated filter (e.g., A-weighting coefficients)\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/sr)\n",
    "    a_weights = np.ones_like(freqs)\n",
    "    # Simplified A-weighting curve (dB adjustment)\n",
    "    for i, f in enumerate(freqs):\n",
    "        if f < 20 or f > 20000:\n",
    "            a_weights[i] = 0  # Attenuate outside human hearing\n",
    "        elif 1000 <= f <= 6000:\n",
    "            a_weights[i] = 1.0  # Emphasize mid frequencies\n",
    "        else:\n",
    "            a_weights[i] = 0.8  # Slight attenuation elsewhere\n",
    "    # Apply to frequency domain\n",
    "    spectrum = np.fft.rfft(signal)\n",
    "    spectrum_weighted = spectrum * a_weights\n",
    "    signal_weighted = np.fft.irfft(spectrum_weighted, n=len(signal))\n",
    "    return signal_weighted\n",
    "\n",
    "# Apply A-weighting\n",
    "y_a_weighted = apply_a_weighting(y, sr)\n",
    "\n",
    "# Compute Leq\n",
    "p_ref = 2e-5  # Reference pressure (Pa)\n",
    "#mean_square = np.mean(y_a_weighted**2)  # Mean squared pressure\n",
    "#leq = 10 * np.log10(mean_square / (p_ref**2))\n",
    "\n",
    "mean_square = np.mean(y_a_weighted**2)  # From A-weighting code\n",
    "leq = 10 * np.log10(mean_square / (p_ref)**2)\n",
    "print(f\"Leq (dBA): {leq:.2f}\")\n",
    "\n",
    "print(f\"Leq (dBA): {leq:.2f}\")\n",
    "\n",
    "# Optional: Play audio to verify\n",
    "ipd.Audio(audio_file)  # No rate needed for file path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d5477",
   "metadata": {},
   "source": [
    "Different reference pressure below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# File path\n",
    "audio_file = \"data\\\\noiseData\\\\Around Arya School(1°16_32_ S 36°49_29_ E).wav\"\n",
    "\n",
    "# Load audio\n",
    "y, sr = librosa.load(audio_file, sr=None)  # y: audio samples, sr: sampling rate\n",
    "\n",
    "# Noise Reduction\n",
    "def spectral_subtraction(audio, sr, noise_start=0.0, noise_end=1.0):\n",
    "    noise_start_sample = int(noise_start * sr)\n",
    "    noise_end_sample = int(noise_end * sr)\n",
    "    noise = audio[noise_start_sample:noise_end_sample]\n",
    "    noise_spec = np.abs(librosa.stft(noise, n_fft=2048, hop_length=512))\n",
    "    noise_mean = np.mean(noise_spec, axis=1, keepdims=True)\n",
    "    audio_spec = np.abs(librosa.stft(audio, n_fft=2048, hop_length=512))\n",
    "    cleaned_spec = np.maximum(audio_spec - noise_mean, 0)\n",
    "    return librosa.istft(cleaned_spec, hop_length=512, length=len(audio))\n",
    "\n",
    "y_cleaned = spectral_subtraction(y, sr, noise_start=0.0, noise_end=1.0)\n",
    "\n",
    "# Low-pass filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def lowpass_filter(data, cutoff_freq, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff_freq, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "y_filtered = lowpass_filter(y_cleaned, cutoff_freq=4000, fs=sr)\n",
    "\n",
    "# Apply A-weighting\n",
    "def apply_a_weighting(signal, sr):\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/sr)\n",
    "    a_weights = np.ones_like(freqs)\n",
    "    for i, f in enumerate(freqs):\n",
    "        if f < 20 or f > 20000:\n",
    "            a_weights[i] = 0\n",
    "        elif 1000 <= f <= 6000:\n",
    "            a_weights[i] = 1.0\n",
    "        else:\n",
    "            a_weights[i] = 0.8\n",
    "    spectrum = np.fft.rfft(signal)\n",
    "    spectrum_weighted = spectrum * a_weights\n",
    "    return np.fft.irfft(spectrum_weighted, n=len(signal))\n",
    "\n",
    "y_a_weighted = apply_a_weighting(y_filtered, sr)\n",
    "\n",
    "# Model reference pressure and calibrate signal\n",
    "p_ref = 2e-5  # Standard reference pressure (Pa)\n",
    "calibration_spl = 94.0  # Calibration level (dB)\n",
    "calibration_pressure = 2e-5 * (10 ** (calibration_spl / 20))  # 1 Pa at 94 dB\n",
    "\n",
    "# Adjust signal amplitude based on calibration\n",
    "# Assume max amplitude of y corresponds to 94 dB (1 Pa), scale accordingly\n",
    "max_amplitude = np.max(np.abs(y))\n",
    "if max_amplitude > 0:\n",
    "    scale_factor = calibration_pressure / max_amplitude  # Scale to 1 Pa\n",
    "    y_a_weighted_calibrated = y_a_weighted * scale_factor\n",
    "else:\n",
    "    y_a_weighted_calibrated = y_a_weighted  # Avoid division by zero\n",
    "\n",
    "# Compute Leq\n",
    "mean_square = np.mean(y_a_weighted_calibrated**2)\n",
    "leq = 10 * np.log10(mean_square / (p_ref**2))\n",
    "\n",
    "print(f\"Modeled Reference Pressure: {p_ref:.6e} Pa (standard)\")\n",
    "print(f\"Calibration Pressure at 94 dB: {calibration_pressure:.6e} Pa\")\n",
    "print(f\"Leq (dBA): {leq:.2f}\")\n",
    "\n",
    "# Optional: Play audio to verify\n",
    "ipd.Audio(audio_file)  # Original audio\n",
    "print(\"Cleaned Audio (first 10s):\")\n",
    "ipd.Audio(y_filtered[:int(10 * sr)], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "\n",
    "# File path\n",
    "audio_file = \"data\\\\test.wav\"\n",
    "\n",
    "# Load audio\n",
    "x_n, sr = librosa.load(audio_file, sr=None)  # x_n: normalized samples, sr: sampling rate\n",
    "\n",
    "# Parameters for framing\n",
    "frame_length = 2048  # Number of samples per frame\n",
    "hop_length = 512    # Number of samples between successive frames\n",
    "\n",
    "# Step 1: Frame the signal and compute the magnitude spectrum\n",
    "# librosa.stft returns the Short-Time Fourier Transform\n",
    "stft = np.abs(librosa.stft(x_n, n_fft=frame_length, hop_length=hop_length))\n",
    "\n",
    "# Get frequencies corresponding to FFT bins\n",
    "freqs = librosa.fft_frequencies(sr=sr, n_fft=frame_length)\n",
    "\n",
    "# Step 2: Compute Spectral Centroid\n",
    "# C[n] = (Σ_k=0^N-1 f_k * |X[k, n]|) / (Σ_k=0^N-1 |X[k, n]|)\n",
    "centroid = librosa.feature.spectral_centroid(S=stft, sr=sr, hop_length=hop_length)\n",
    "\n",
    "# Step 3: Compute Spectral Bandwidth\n",
    "# B[n] = sqrt(Σ_k=0^N-1 (f_k - C[n])^2 * |X[k, n]|) / (Σ_k=0^N-1 |X[k, n]|)\n",
    "bandwidth = librosa.feature.spectral_bandwidth(S=stft, sr=sr, hop_length=hop_length, centroid=centroid)\n",
    "\n",
    "# Time axis for frames\n",
    "frames = np.arange(centroid.shape[1])\n",
    "times = librosa.frames_to_time(frames, sr=sr, hop_length=hop_length)\n",
    "\n",
    "# Output results\n",
    "print(\"Spectral Centroid (Hz) for each frame:\")\n",
    "for t, c in zip(times, centroid[0]):\n",
    "    print(f\"Time: {t:.3f}s, Centroid: {c:.2f} Hz\")\n",
    "\n",
    "print(\"\\nSpectral Bandwidth (Hz) for each frame:\")\n",
    "for t, b in zip(times, bandwidth[0]):\n",
    "    print(f\"Time: {t:.3f}s, Bandwidth: {b:.2f} Hz\")\n",
    "\n",
    "# Optional: Play audio to verify\n",
    "ipd.Audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "# File path\n",
    "audio_file = \"data\\\\test.wav\"\n",
    "sampling_rate = 44100\n",
    "\n",
    "# Load audio\n",
    "x_n, sr = librosa.load(audio_file, sr=sampling_rate)  # x_n: normalized samples, sr: sampling rate\n",
    "\n",
    "# Parameters for framing\n",
    "frame_length = 2048  # Number of samples per frame\n",
    "hop_length = 512    # Number of samples between successive frames\n",
    "\n",
    "# Step 1: Compute magnitude spectrum\n",
    "stft = np.abs(librosa.stft(x_n, n_fft=frame_length, hop_length=hop_length))\n",
    "\n",
    "# Step 2: Extract timbre features\n",
    "centroid = librosa.feature.spectral_centroid(S=stft, sr=sr, hop_length=hop_length)  # 2D array (1, n_frames)\n",
    "bandwidth = librosa.feature.spectral_bandwidth(S=stft, sr=sr, hop_length=hop_length, centroid=centroid)  # 1D array\n",
    "\n",
    "# Combine features into a single feature vector for change detection\n",
    "features = np.vstack((centroid[0], bandwidth)).T  # Shape: (n_frames, 2)\n",
    "\n",
    "# Step 3: Detect change points using a simple difference method\n",
    "# Compute the difference between consecutive frames\n",
    "feature_diff = np.linalg.norm(features[1:] - features[:-1], axis=1)  # Euclidean distance\n",
    "\n",
    "# Smooth the difference to reduce noise\n",
    "window_size = 5\n",
    "smoothed_diff = np.convolve(feature_diff, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "# Identify local maxima in the difference (potential change points)\n",
    "change_points_idx = argrelextrema(smoothed_diff, np.greater, order=3)[0]\n",
    "change_points_time = librosa.frames_to_time(change_points_idx, sr=sr, hop_length=hop_length)\n",
    "\n",
    "# Add start and end points\n",
    "change_points_time = np.insert(change_points_time, 0, 0)\n",
    "change_points_time = np.append(change_points_time, librosa.get_duration(y=x_n, sr=sr))\n",
    "\n",
    "# Step 4: Segment the audio\n",
    "segments = []\n",
    "for i in range(len(change_points_time) - 1):\n",
    "    start_time = change_points_time[i]\n",
    "    end_time = change_points_time[i + 1]\n",
    "    start_sample = int(start_time * sr)\n",
    "    end_sample = int(end_time * sr)\n",
    "    segment = x_n[start_sample:end_sample]\n",
    "    segments.append((start_time, end_time, segment))\n",
    "\n",
    "# Output segment information\n",
    "print(\"Detected Segments:\")\n",
    "for i, (start, end, _) in enumerate(segments):\n",
    "    print(f\"Segment {i + 1}: {start:.3f}s to {end:.3f}s\")\n",
    "\n",
    "# Optional: Save or play segments\n",
    "for i, (start, end, segment) in enumerate(segments):\n",
    "    output_file = f\"segment_{i + 1}.wav\"\n",
    "    librosa.output.write_wav(output_file, segment, sr)\n",
    "    print(f\"Saved {output_file}\")\n",
    "    # ipd.Audio(segment, rate=sr)\n",
    "\n",
    "# Optional: Play original audio to verify\n",
    "ipd.Audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02859870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "from scipy.signal import argrelextrema\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# File path\n",
    "audio_file = \"data\\\\test.wav\"\n",
    "\n",
    "# Load audio\n",
    "x_n, sr = librosa.load(audio_file, sr=None)  # x_n: normalized samples, sr: sampling rate\n",
    "total_duration = librosa.get_duration(y=x_n, sr=sr)\n",
    "\n",
    "# Parameters for framing\n",
    "frame_length = 2048  # Number of samples per frame\n",
    "hop_length = 512    # Number of samples between successive frames\n",
    "\n",
    "# Step 1: Compute magnitude spectrum\n",
    "stft = np.abs(librosa.stft(x_n, n_fft=frame_length, hop_length=hop_length))\n",
    "\n",
    "# Step 2: Extract timbre features\n",
    "centroid = librosa.feature.spectral_centroid(S=stft, sr=sr, hop_length=hop_length)\n",
    "bandwidth = librosa.feature.spectral_bandwidth(S=stft, sr=sr, hop_length=hop_length, centroid=centroid)\n",
    "\n",
    "# Combine features into a single feature vector for change detection\n",
    "features = np.vstack((centroid, bandwidth)).T  # Shape: (n_frames, 2)\n",
    "\n",
    "# Step 3: Detect change points with threshold\n",
    "# Compute the difference between consecutive frames\n",
    "feature_diff = np.linalg.norm(features[1:] - features[:-1], axis=1)  # Euclidean distance\n",
    "\n",
    "# Smooth the difference to reduce noise\n",
    "window_size = 10  # Increased to smooth more aggressively\n",
    "smoothed_diff = np.convolve(feature_diff, np.ones(window_size)/window_size, mode='same')\n",
    "\n",
    "# Set a threshold (e.g., 95th percentile of smoothed differences)\n",
    "threshold = np.percentile(smoothed_diff, 95)  # Adjust percentile (e.g., 90-98) based on audio\n",
    "change_points_idx = np.where(smoothed_diff > threshold)[0]\n",
    "\n",
    "# Convert to time\n",
    "change_points_time = librosa.frames_to_time(change_points_idx, sr=sr, hop_length=hop_length)\n",
    "\n",
    "# Add start and end points\n",
    "change_points_time = np.insert(change_points_time, 0, 0)\n",
    "change_points_time = np.append(change_points_time, total_duration)\n",
    "\n",
    "# Step 4: Segment the audio with minimum 10-second duration\n",
    "min_duration = 5.0  # Minimum segment duration in seconds\n",
    "segments = []\n",
    "current_start = change_points_time[0]\n",
    "current_end = change_points_time[0]\n",
    "\n",
    "for end_time in change_points_time[1:]:\n",
    "    duration = end_time - current_start\n",
    "    if duration >= min_duration or end_time == total_duration:\n",
    "        current_end = end_time\n",
    "        start_sample = int(current_start * sr)\n",
    "        end_sample = min(int(current_end * sr), len(x_n))  # Ensure no out-of-bounds\n",
    "        segment = x_n[start_sample:end_sample]\n",
    "        segments.append((current_start, current_end, segment))\n",
    "        current_start = current_end\n",
    "    else:\n",
    "        continue  # Merge with next segment\n",
    "\n",
    "# If the last segment is less than 10s and not the end, extend to total duration\n",
    "if len(segments) > 0 and (total_duration - segments[-1][1]) < min_duration:\n",
    "    start_sample = int(segments[-1][1] * sr)\n",
    "    end_sample = len(x_n)\n",
    "    segment = x_n[start_sample:end_sample]\n",
    "    segments[-1] = (segments[-1][0], total_duration, np.concatenate((segments[-1][2], segment)))\n",
    "\n",
    "# Output folder (e.g., 'test' from 'test.wav')\n",
    "folder_name = os.path.splitext(os.path.basename(audio_file))[0]  # Extract 'test' from 'test.wav'\n",
    "output_folder = os.path.join(os.path.dirname(audio_file), folder_name)\n",
    "os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
    "\n",
    "# Output segment information\n",
    "print(\"Detected Segments:\")\n",
    "for i, (start, end, _) in enumerate(segments):\n",
    "    print(f\"Segment {i + 1}: {start:.3f}s to {end:.3f}s (Duration: {end - start:.3f}s)\")\n",
    "\n",
    "# Save segments to the folder\n",
    "for i, (start, end, segment) in enumerate(segments):\n",
    "    output_file = os.path.join(output_folder, f\"segment_{i + 1}.wav\")\n",
    "    sf.write(output_file, segment, sr)\n",
    "    print(f\"Saved {output_file}\")\n",
    "    # ipd.Audio(segment, rate=sr)\n",
    "\n",
    "# Optional: Visualize smoothed difference to tune threshold\n",
    "import matplotlib.pyplot as plt\n",
    "times = librosa.frames_to_time(np.arange(len(smoothed_diff)), sr=sr, hop_length=hop_length)\n",
    "plt.plot(times, smoothed_diff, label='Smoothed Difference')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label=f'Threshold ({threshold:.2f})')\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Difference\")\n",
    "plt.title(\"Smoothed Feature Difference with Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Play original audio to verify\n",
    "ipd.Audio(audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0538b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "def apply_a_weighting(signal, sr):\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/sr)\n",
    "    a_weights = np.ones_like(freqs)\n",
    "    for i, f in enumerate(freqs):\n",
    "        if f < 20 or f > 20000:\n",
    "            a_weights[i] = 0  # Attenuate outside human hearing\n",
    "        elif 1000 <= f <= 6000:\n",
    "            a_weights[i] = 1.0  # Emphasize mid frequencies\n",
    "        else:\n",
    "            a_weights[i] = 0.8  # Slight attenuation elsewhere\n",
    "    spectrum = np.fft.rfft(signal)\n",
    "    spectrum_weighted = spectrum * a_weights\n",
    "    signal_weighted = np.fft.irfft(spectrum_weighted, n=len(signal))\n",
    "    return signal_weighted\n",
    "\n",
    "\n",
    "folder_path = \"data\\\\noiseData\"  \n",
    "output_csv = \"leq_results.csv\"\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            y, sr = librosa.load(file_path, sr=None)  \n",
    "            \n",
    "            y_a_weighted = apply_a_weighting(y, sr)\n",
    "            \n",
    "            p_ref = 2e-5  \n",
    "            mean_square = np.mean(y_a_weighted**2)\n",
    "            leq = 10 * np.log10(mean_square / (p_ref**2))\n",
    "            \n",
    "            results.append([filename, leq])\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            results.append([filename, float('nan')])\n",
    "\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results, columns=['Filename', 'Leq_dBA'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "else:\n",
    "    print(\"No valid WAV files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a88d5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "\n",
    "REF_PRESSURE = 20e-6\n",
    "MIN_RMS_THRESHOLD = 1e-10\n",
    "\n",
    "def calculate_leq(wav_data, sample_rate):\n",
    "    rms = np.sqrt(np.mean(np.square(wav_data)))\n",
    "    rms = max(rms, MIN_RMS_THRESHOLD)\n",
    "    leq = 20 * np.log10(rms / REF_PRESSURE)\n",
    "    return leq\n",
    "\n",
    "folder_path = \"data\\\\newwav\" \n",
    "output_csv = \"leq_results2.csv\"\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "    \n",
    "        try:\n",
    "            sample_rate, data = wavfile.read(file_path)\n",
    "            if data.ndim > 1:  \n",
    "                data = np.mean(data, axis=1)\n",
    "            \n",
    "            \n",
    "            if np.all(data == 0):\n",
    "                print(f\"Warning: {filename} is silent (all zeros). Skipping detailed analysis.\")\n",
    "                results.append([filename, float('nan'), float('nan'), float('nan')])\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            max_amplitude = np.max(np.abs(data))\n",
    "            if max_amplitude > 0 and max_amplitude < 1e-5:  \n",
    "                data = data / max_amplitude * 32767  \n",
    "            \n",
    "            \n",
    "            window_size = int(0.1 * sample_rate) \n",
    "            leq_values = []\n",
    "            \n",
    "            for i in range(0, len(data), window_size):\n",
    "                segment = data[i:i + window_size]\n",
    "                if len(segment) == window_size:\n",
    "                    leq = calculate_leq(segment, sample_rate)\n",
    "                    leq_values.append(leq)\n",
    "            \n",
    "            if leq_values:\n",
    "                max_leq = np.max(leq_values)\n",
    "                min_leq = np.min(leq_values)\n",
    "                avg_leq = np.mean(leq_values)\n",
    "                results.append([filename, max_leq, min_leq, avg_leq])\n",
    "            else:\n",
    "                results.append([filename, float('nan'), float('nan'), float('nan')])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            results.append([filename, float('nan'), float('nan'), float('nan')])\n",
    "\n",
    "\n",
    "if results:\n",
    "    df = pd.DataFrame(results, columns=['Filename', 'Max_Leq_dB', 'Min_Leq_dB', 'Avg_Leq_dB'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "else:\n",
    "    print(\"No valid WAV files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "# Function to apply A-weighting (approximation)\n",
    "def apply_a_weighting(signal, sr):\n",
    "    freqs = np.fft.rfftfreq(len(signal), d=1/sr)\n",
    "    a_weights = np.ones_like(freqs)\n",
    "    for i, f in enumerate(freqs):\n",
    "        if f < 20 or f > 20000:\n",
    "            a_weights[i] = 0  # Attenuate outside human hearing\n",
    "        elif 1000 <= f <= 6000:\n",
    "            a_weights[i] = 1.0  # Emphasize mid frequencies\n",
    "        else:\n",
    "            a_weights[i] = 0.8  # Slight attenuation elsewhere\n",
    "    spectrum = np.fft.rfft(signal)\n",
    "    spectrum_weighted = spectrum * a_weights\n",
    "    signal_weighted = np.fft.irfft(spectrum_weighted, n=len(signal))\n",
    "    return signal_weighted\n",
    "\n",
    "# Specify the folder containing WAV files\n",
    "folder_path = \"data\\\\noiseData\" \n",
    "output_csv = \"leq_result.csv\"\n",
    "\n",
    "# Lists to store results\n",
    "results = []\n",
    "\n",
    "# Loop through all WAV files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load audio\n",
    "        try:\n",
    "            y, sr = librosa.load(file_path, sr=None)  # y: audio samples, sr: sampling rate\n",
    "            \n",
    "            # Apply A-weighting\n",
    "            y_a_weighted = apply_a_weighting(y, sr)\n",
    "            \n",
    "            # Calculate Leq for short segments (e.g., 0.1s windows)\n",
    "            window_size = int(0.1 * sr)  # 0.1 seconds\n",
    "            leq_values = []\n",
    "            \n",
    "            for i in range(0, len(y_a_weighted), window_size):\n",
    "                segment = y_a_weighted[i:i + window_size]\n",
    "                if len(segment) == window_size:\n",
    "                    # Compute Leq for the segment\n",
    "                    p_ref = 2e-5  # Reference pressure (Pa)\n",
    "                    mean_square = np.mean(segment**2)  # Mean squared pressure\n",
    "                    leq = 10 * np.log10(mean_square / (p_ref**2))\n",
    "                    leq_values.append(leq)\n",
    "            \n",
    "            if leq_values:\n",
    "                max_leq = np.max(leq_values)\n",
    "                min_leq = np.min(leq_values)\n",
    "                avg_leq = np.mean(leq_values)\n",
    "                results.append([filename, max_leq, min_leq, avg_leq])\n",
    "            else:\n",
    "                results.append([filename, float('nan'), float('nan'), float('nan')])\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            results.append([filename, float('nan'), float('nan'), float('nan')])\n",
    "\n",
    "# Create a DataFrame and save to CSV\n",
    "if results:\n",
    "    df = pd.DataFrame(results, columns=['Filename', 'Max_Leq_dBA', 'Min_Leq_dBA', 'Avg_Leq_dBA'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "else:\n",
    "    print(\"No valid WAV files processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057f1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "def apply_a_weighting(signal, sr):\n",
    "    \"\"\"\n",
    "    Apply A-weighting to a time-domain signal using librosa's A-weighting filter.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): Input audio signal\n",
    "        sr (int): Sampling rate in Hz\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A-weighted signal\n",
    "    \"\"\"\n",
    "    # Compute FFT frequencies\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=1/sr)\n",
    "    \n",
    "    # Get A-weighting values (in dB) for the frequencies\n",
    "    a_weights_db = librosa.A_weighting(freqs)\n",
    "    \n",
    "    # Convert dB weights to linear scale\n",
    "    a_weights = 10 ** (a_weights_db / 20.0)\n",
    "    \n",
    "    # Apply A-weighting in frequency domain\n",
    "    spectrum = np.fft.rfft(signal)\n",
    "    spectrum_weighted = spectrum * a_weights\n",
    "    \n",
    "    # Inverse FFT to get back to time domain\n",
    "    signal_weighted = np.fft.irfft(spectrum_weighted, n=n)\n",
    "    \n",
    "    # Ensure output length matches input (handle any length mismatches)\n",
    "    if len(signal_weighted) > len(signal):\n",
    "        signal_weighted = signal_weighted[:len(signal)]\n",
    "    elif len(signal_weighted) < len(signal):\n",
    "        signal_weighted = np.pad(signal_weighted, (0, len(signal) - len(signal_weighted)), 'constant')\n",
    "    \n",
    "    return signal_weighted\n",
    "\n",
    "def calculate_leq(signal, sr, p_ref=2e-5):\n",
    "    \"\"\"\n",
    "    Calculate Leq (equivalent continuous sound level) in dB(A).\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): A-weighted audio signal\n",
    "        sr (int): Sampling rate in Hz\n",
    "        p_ref (float): Reference pressure (default: 2e-5 Pa)\n",
    "    \n",
    "    Returns:\n",
    "        float: Leq value in dB(A)\n",
    "    \"\"\"\n",
    "    # Compute mean square of the A-weighted signal\n",
    "    mean_square = np.mean(signal**2)\n",
    "    \n",
    "    # Avoid log of zero or negative values\n",
    "    if mean_square <= 0:\n",
    "        return float('nan')\n",
    "    \n",
    "    # Calculate Leq in dB(A)\n",
    "    leq = 10 * np.log10(mean_square / (p_ref**2))\n",
    "    return leq\n",
    "\n",
    "def process_audio_files(folder_path, output_csv):\n",
    "    \"\"\"\n",
    "    Process WAV files in a folder, compute A-weighted Leq, and save results to CSV.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to folder containing WAV files\n",
    "        output_csv (str): Path to output CSV file\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                # Load audio file\n",
    "                y, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "                \n",
    "                # Apply A-weighting\n",
    "                y_a_weighted = apply_a_weighting(y, sr)\n",
    "                \n",
    "                # Calculate Leq\n",
    "                leq = calculate_leq(y_a_weighted, sr)\n",
    "                \n",
    "                results.append([filename, leq])\n",
    "                print(f\"Processed {filename}: Leq = {leq:.2f} dB(A)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                results.append([filename, float('nan')])\n",
    "    \n",
    "    # Save results to CSV\n",
    "    if results:\n",
    "        df = pd.DataFrame(results, columns=['Filename', 'Leq_dBA'])\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"Results saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"No valid WAV files processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"data\\\\noiseData\"  # Adjust path as needed\n",
    "    output_csv = \"new_leq_results.csv\"\n",
    "    \n",
    "    # Ensure folder exists\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "    else:\n",
    "        process_audio_files(folder_path, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba444ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEQ STILL DIFFERES BY MUCH WITH THE MEASUREMENTS FROM THE SOUND LEVEL METER\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import scipy.signal as signal\n",
    "\n",
    "def apply_a_weighting(signal, sr):\n",
    "    \"\"\"\n",
    "    Apply A-weighting to a time-domain signal using librosa's A-weighting filter.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): Input audio signal\n",
    "        sr (int): Sampling rate in Hz\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: A-weighted signal\n",
    "    \"\"\"\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=1/sr)\n",
    "    a_weights_db = librosa.A_weighting(freqs)\n",
    "    a_weights = 10 ** (a_weights_db / 20.0)\n",
    "    spectrum = np.fft.rfft(signal)\n",
    "    spectrum_weighted = spectrum * a_weights\n",
    "    signal_weighted = np.fft.irfft(spectrum_weighted, n=n)\n",
    "    \n",
    "    if len(signal_weighted) > len(signal):\n",
    "        signal_weighted = signal_weighted[:len(signal)]\n",
    "    elif len(signal_weighted) < len(signal):\n",
    "        signal_weighted = np.pad(signal_weighted, (0, len(signal) - len(signal_weighted)), 'constant')\n",
    "    \n",
    "    return signal_weighted\n",
    "\n",
    "def apply_time_weighting(signal, sr, time_weighting=None):\n",
    "    \"\"\"\n",
    "    Apply time-weighting (fast or slow) to a signal.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): Input signal\n",
    "        sr (int): Sampling rate in Hz\n",
    "        time_weighting (str): 'fast' (125 ms), 'slow' (1 s), or None\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Time-weighted signal (squared for Leq calculation)\n",
    "    \"\"\"\n",
    "    if time_weighting is None:\n",
    "        return signal**2\n",
    "    \n",
    "    # Time constants\n",
    "    tau = 0.125 if time_weighting.lower() == 'fast' else 1.0\n",
    "    alpha = 1 - np.exp(-1/(sr * tau))\n",
    "    \n",
    "    # Exponential moving average (squared signal for Leq)\n",
    "    b = [alpha]\n",
    "    a = [1, -(1 - alpha)]\n",
    "    return signal.lfilter(b, a, signal**2)\n",
    "\n",
    "def calculate_leq(signal, sr, calibration_factor=1.0, time_weighting=None, p_ref=2e-5):\n",
    "    \"\"\"\n",
    "    Calculate Leq in dB(A) with calibration and optional time-weighting.\n",
    "    \n",
    "    Parameters:\n",
    "        signal (np.ndarray): Input audio signal\n",
    "        sr (int): Sampling rate in Hz\n",
    "        calibration_factor (float): Scaling factor to match SPL (default: 1.0)\n",
    "        time_weighting (str): 'fast', 'slow', or None\n",
    "        p_ref (float): Reference pressure (default: 2e-5 Pa)\n",
    "    \n",
    "    Returns:\n",
    "        float: Leq value in dB(A)\n",
    "    \"\"\"\n",
    "    # Apply calibration\n",
    "    signal = signal * calibration_factor\n",
    "    \n",
    "    # Print signal diagnostics\n",
    "    peak_amplitude = np.max(np.abs(signal))\n",
    "    rms_unweighted = np.sqrt(np.mean(signal**2))\n",
    "    print(f\"  Peak amplitude: {peak_amplitude:.4f}\")\n",
    "    print(f\"  RMS (unweighted): {20 * np.log10(rms_unweighted / p_ref):.2f} dB\")\n",
    "    \n",
    "    # Apply A-weighting\n",
    "    signal_weighted = apply_a_weighting(signal, sr)\n",
    "    \n",
    "    # Print A-weighted RMS\n",
    "    rms_weighted = np.sqrt(np.mean(signal_weighted**2))\n",
    "    print(f\"  RMS (A-weighted): {20 * np.log10(rms_weighted / p_ref):.2f} dB\")\n",
    "    \n",
    "    # Apply time-weighting to squared signal\n",
    "    signal_squared = apply_time_weighting(signal_weighted, sr, time_weighting)\n",
    "    \n",
    "    # Compute mean square\n",
    "    mean_square = np.mean(signal_squared)\n",
    "    \n",
    "    if mean_square <= 0:\n",
    "        print(\"  Warning: Mean square is zero or negative, returning NaN\")\n",
    "        return float('nan')\n",
    "    \n",
    "    leq = 10 * np.log10(mean_square / (p_ref**2))\n",
    "    return leq\n",
    "\n",
    "def calibrate_signal(reference_file, sr, reference_spl=94.0):\n",
    "    \"\"\"\n",
    "    Calculate calibration factor using a reference WAV file (e.g., 1 kHz tone at 94 dB SPL).\n",
    "    \n",
    "    Parameters:\n",
    "        reference_file (str): Path to reference WAV file\n",
    "        sr (int): Sampling rate in Hz\n",
    "        reference_spl (float): Known SPL of reference signal (default: 94 dB)\n",
    "    \n",
    "    Returns:\n",
    "        float: Calibration factor\n",
    "    \"\"\"\n",
    "    y_ref, sr_ref = librosa.load(reference_file, sr=sr, mono=True)\n",
    "    y_ref_weighted = apply_a_weighting(y_ref, sr_ref)\n",
    "    mean_square = np.mean(y_ref_weighted**2)\n",
    "    if mean_square <= 0:\n",
    "        print(\"Warning: Reference signal mean square is zero, using default calibration factor\")\n",
    "        return 1.0\n",
    "    measured_spl = 10 * np.log10(mean_square / (2e-5**2))\n",
    "    calibration_factor = 10 ** ((reference_spl - measured_spl) / 20.0)\n",
    "    return calibration_factor\n",
    "\n",
    "def process_audio_files(folder_path, output_csv, calibration_file=None, time_weighting=None):\n",
    "    \"\"\"\n",
    "    Process WAV files, compute A-weighted Leq, and save results to CSV.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str): Path to folder containing WAV files\n",
    "        output_csv (str): Path to output CSV file\n",
    "        calibration_file (str): Path to reference WAV file for calibration (optional)\n",
    "        time_weighting (str): 'fast', 'slow', or None\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Calculate calibration factor if provided\n",
    "    calibration_factor = 1.0\n",
    "    if calibration_file:\n",
    "        try:\n",
    "            calibration_factor = calibrate_signal(calibration_file, sr=44100)\n",
    "            print(f\"Calibration factor: {calibration_factor:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error calibrating with {calibration_file}: {e}\")\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            try:\n",
    "                print(f\"\\nProcessing {filename}\")\n",
    "                y, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "                leq = calculate_leq(y, sr, calibration_factor, time_weighting)\n",
    "                results.append([filename, leq])\n",
    "                print(f\"  Leq = {leq:.2f} dB(A)\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "                results.append([filename, float('nan')])\n",
    "    \n",
    "    if results:\n",
    "        df = pd.DataFrame(results, columns=['Filename', 'Leq_dBA'])\n",
    "        df.to_csv(output_csv, index=False)\n",
    "        print(f\"\\nResults saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"No valid WAV files processed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder_path = \"data/noiseData\"  # Adjust path\n",
    "    output_csv = \"leq_results.csv\"\n",
    "    calibration_file = None  # Set to path of reference WAV file (e.g., 94 dB SPL tone)\n",
    "    time_weighting = 'slow'  # Options: 'fast', 'slow', or None\n",
    "    \n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder {folder_path} does not exist.\")\n",
    "    else:\n",
    "        process_audio_files(folder_path, output_csv, calibration_file, time_weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1533784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from acoustics import Signal\n",
    "\n",
    "# Load WAV file\n",
    "y, sr = librosa.load('data\\\\noiseData\\\\Around Baba Dogo Rd(1°14_51_S 36°52_26_E).wav', sr=None, mono=True)\n",
    "\n",
    "# Convert to pressure (assume 1 Pa for full scale)\n",
    "p_scale = 1.0  # Adjust based on calibration\n",
    "p = y * p_scale\n",
    "\n",
    "# Define A-weighting function\n",
    "def a_weighting(f):\n",
    "    f = np.asarray(f)\n",
    "    num = (12194**2) * (f**4)\n",
    "    den = (f**2 + 20.6**2) * np.sqrt((f**2 + 107.7**2) * (f**2 + 737.9**2)) * (f**2 + 12194**2)\n",
    "    weight = num / den\n",
    "    weight_db = 20 * np.log10(weight) + 2.0  # Normalize at 1 kHz\n",
    "    return weight_db\n",
    "\n",
    "# Compute STFT\n",
    "n_fft = 2048\n",
    "hop_length = 512\n",
    "stft = librosa.stft(p, n_fft=n_fft, hop_length=hop_length)\n",
    "freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "\n",
    "# Apply A-weighting\n",
    "weights_db = a_weighting(freqs)\n",
    "weights = 10**(weights_db / 20.0)\n",
    "stft_a_weighted = stft * weights[:, np.newaxis]\n",
    "\n",
    "# Convert back to time domain using librosa.istft\n",
    "p_a_weighted = librosa.istft(stft_a_weighted, hop_length=hop_length, length=len(p))\n",
    "\n",
    "# Calculate Leq\n",
    "p0 = 2e-5\n",
    "mean_squared_pressure = np.mean(p_a_weighted**2)\n",
    "leq = 10 * np.log10(mean_squared_pressure / (p0**2))\n",
    "\n",
    "# Use acoustics' Leq method\n",
    "signal_a_weighted = Signal(p_a_weighted, fs=sr)\n",
    "leq_acoustics = signal_a_weighted.leq()\n",
    "\n",
    "print(f\"A-weighted Leq (manual): {leq:.2f} dB(A)\")\n",
    "print(f\"A-weighted Leq (acoustics): {leq_acoustics:.2f} dB(A)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4499667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error designing filter: tf2sos() got an unexpected keyword argument 'gain'\n",
      "Using fallback Butterworth filter\n",
      "Total A-weighted Leq: 76.80 dB(A)\n",
      "A-weighted Leq (full signal, acoustics): 76.80 dB(A)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from acoustics import Signal\n",
    "from scipy.signal import butter, sosfilt, sosfreqz\n",
    "import scipy.signal as signal\n",
    "\n",
    "# Load WAV file\n",
    "y, sr = librosa.load('data\\\\noiseData\\\\Around Baba Dogo Rd(1°14_51_S 36°52_26_E).wav', sr=None, mono=True)\n",
    "\n",
    "# Convert to pressure (adjust p_scale with calibration, e.g., 94 dB SPL = 1 Pa)\n",
    "p_scale = 1.4\n",
    "p = y * p_scale\n",
    "\n",
    "# Design A-weighting filter (IEC 61672-1 compliant)\n",
    "def a_weighting_filter(fs):\n",
    "    \"\"\"\n",
    "    Design an IIR filter for A-weighting based on IEC 61672-1.\n",
    "    Parameters:\n",
    "        fs: Sampling frequency (Hz)\n",
    "    Returns:\n",
    "        sos: Second-order sections for filtering\n",
    "    \"\"\"\n",
    "    # Pole and zero frequencies (Hz) from IEC 61672-1\n",
    "    f1 = 20.6  # Low-frequency pole\n",
    "    f2 = 107.7\n",
    "    f3 = 737.9\n",
    "    f4 = 12194.0  # High-frequency pole\n",
    "\n",
    "    # Analog filter: zeros at 0 (double), f4 (double); poles at f1 (double), f2, f3, f4 (double)\n",
    "    zeros = np.array([0, 0, -2*np.pi*f4, -2*np.pi*f4], dtype=np.float64)\n",
    "    poles = np.array([-2*np.pi*f1, -2*np.pi*f1, -2*np.pi*f2, -2*np.pi*f3, -2*np.pi*f4, -2*np.pi*f4], dtype=np.float64)\n",
    "    gain = (2*np.pi*f4)**4 / np.sqrt((2*np.pi*f2)*(2*np.pi*f3))\n",
    "\n",
    "    try:\n",
    "        # Convert to transfer function\n",
    "        b, a = signal.zpk2tf(zeros, poles, gain)\n",
    "        # Convert to SOS for stability\n",
    "        sos = signal.tf2sos(b, a, analog=False)\n",
    "        # Normalize gain at 1 kHz\n",
    "        w, h = sosfreqz(sos, worN=2048, fs=fs)\n",
    "        freq_1khz = np.argmin(np.abs(w - 1000))\n",
    "        gain_1khz = np.abs(h[freq_1khz])\n",
    "        sos = signal.tf2sos(b, a, analog=False, gain=1/gain_1khz)\n",
    "    except Exception as e:\n",
    "        print(f\"Error designing filter: {e}\")\n",
    "        # Fallback to a simpler Butterworth approximation if needed\n",
    "        sos = butter(4, [20, 20000], btype='band', fs=fs, output='sos')\n",
    "        print(\"Using fallback Butterworth filter\")\n",
    "\n",
    "    return sos\n",
    "\n",
    "# Create A-weighting filter\n",
    "try:\n",
    "    sos = a_weighting_filter(sr)\n",
    "except Exception as e:\n",
    "    print(f\"Filter creation failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Window parameters\n",
    "window_size = int(sr * 10.0)  # 1-second windows\n",
    "p0 = 2e-5  # Reference pressure (20 µPa)\n",
    "leqs = []\n",
    "\n",
    "# Process each 1-second window\n",
    "for i in range(0, len(p), window_size):\n",
    "    segment = p[i:i+window_size]\n",
    "    if len(segment) < window_size // 2:  # Skip short segments\n",
    "        continue\n",
    "    # Apply A-weighting filter\n",
    "    try:\n",
    "        segment_a_weighted = sosfilt(sos, segment)\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying filter to segment {i//window_size}: {e}\")\n",
    "        continue\n",
    "    # Calculate Leq for the segment\n",
    "    mean_squared_pressure = np.mean(segment_a_weighted**2)\n",
    "    if mean_squared_pressure <= 0:  # Avoid log of zero or negative\n",
    "        continue\n",
    "    leq = 10 * np.log10(mean_squared_pressure / (p0**2))\n",
    "    if np.isfinite(leq):  # Check for valid Leq\n",
    "        leqs.append(leq)\n",
    "\n",
    "# Compute total Leq (logarithmic average)\n",
    "if leqs:\n",
    "    leq_total = 10 * np.log10(np.mean(10**(np.array(leqs)/10)))\n",
    "    print(f\"Total A-weighted Leq: {leq_total:.2f} dB(A)\")\n",
    "else:\n",
    "    print(\"No valid windows processed\")\n",
    "\n",
    "# Optional: Compute Leq for the entire signal using acoustics\n",
    "try:\n",
    "    signal_full = Signal(p, fs=sr)\n",
    "    p_a_weighted = sosfilt(sos, p)\n",
    "    signal_a_weighted = Signal(p_a_weighted, fs=sr)\n",
    "    leq_acoustics = signal_a_weighted.leq()\n",
    "    print(f\"A-weighted Leq (full signal, acoustics): {leq_acoustics:.2f} dB(A)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error computing full-signal Leq: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8798c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error designing filter: tf2sos() got an unexpected keyword argument 'gain'\n",
      "Using fallback Butterworth filter\n",
      "Total A-weighted Leq: 77.40 dB(A)\n",
      "A-weighted Leq (full signal, acoustics): 77.40 dB(A)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from acoustics import Signal\n",
    "from scipy.signal import butter, sosfilt, sosfreqz\n",
    "import scipy.signal as signal\n",
    "\n",
    "# Load WAV file\n",
    "y, sr = librosa.load('data\\\\noiseData\\\\Around Baba Dogo Rd(1°14_51_S 36°52_26_E).wav', sr=44100, mono=True)\n",
    "\n",
    "# Convert to pressure (adjust p_scale with calibration, e.g., 94 dB SPL = 1 Pa)\n",
    "p_scale = 1.5  # Placeholder: calibrate using a known reference tone\n",
    "p = y * p_scale\n",
    "\n",
    "# Design A-weighting filter (IEC 61672-1 compliant)\n",
    "def a_weighting_filter(fs):\n",
    "    \"\"\"\n",
    "    Design an IIR filter for A-weighting based on IEC 61672-1.\n",
    "    Parameters:\n",
    "        fs: Sampling frequency (Hz)\n",
    "    Returns:\n",
    "        sos: Second-order sections for filtering\n",
    "    \"\"\"\n",
    "    # Pole and zero frequencies (Hz) from IEC 61672-1\n",
    "    f1 = 20.6  # Low-frequency pole\n",
    "    f2 = 107.7\n",
    "    f3 = 737.9\n",
    "    f4 = 12194.0  # High-frequency pole\n",
    "\n",
    "    # Analog filter: zeros at 0 (double), f4 (double); poles at f1 (double), f2, f3, f4 (double)\n",
    "    zeros = np.array([0, 0, -2*np.pi*f4, -2*np.pi*f4], dtype=np.float64)\n",
    "    poles = np.array([-2*np.pi*f1, -2*np.pi*f1, -2*np.pi*f2, -2*np.pi*f3, -2*np.pi*f4, -2*np.pi*f4], dtype=np.float64)\n",
    "    gain = (2*np.pi*f4)**4 / np.sqrt((2*np.pi*f2)*(2*np.pi*f3))\n",
    "\n",
    "    try:\n",
    "        # Convert to transfer function\n",
    "        b, a = signal.zpk2tf(zeros, poles, gain)\n",
    "        # Convert to SOS for stability\n",
    "        sos = signal.tf2sos(b, a, analog=False)\n",
    "        # Normalize gain at 1 kHz\n",
    "        w, h = sosfreqz(sos, worN=2048, fs=fs)\n",
    "        freq_1khz = np.argmin(np.abs(w - 1000))\n",
    "        gain_1khz = np.abs(h[freq_1khz])\n",
    "        sos = signal.tf2sos(b, a, analog=False, gain=1/gain_1khz)\n",
    "    except Exception as e:\n",
    "        print(f\"Error designing filter: {e}\")\n",
    "        # Fallback to a simpler Butterworth approximation if needed\n",
    "        sos = butter(4, [20, 20000], btype='band', fs=fs, output='sos')\n",
    "        print(\"Using fallback Butterworth filter\")\n",
    "\n",
    "    return sos\n",
    "\n",
    "# Create A-weighting filter\n",
    "try:\n",
    "    sos = a_weighting_filter(sr)\n",
    "except Exception as e:\n",
    "    print(f\"Filter creation failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Window parameters\n",
    "window_size = int(sr * 1.0)  # 1-second windows\n",
    "p0 = 2e-5  # Reference pressure (20 µPa)\n",
    "leqs = []\n",
    "\n",
    "# Process each 1-second window\n",
    "for i in range(0, len(p), window_size):\n",
    "    segment = p[i:i+window_size]\n",
    "    if len(segment) < window_size // 2:  # Skip short segments\n",
    "        continue\n",
    "    # Apply A-weighting filter\n",
    "    try:\n",
    "        segment_a_weighted = sosfilt(sos, segment)\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying filter to segment {i//window_size}: {e}\")\n",
    "        continue\n",
    "    # Calculate Leq for the segment\n",
    "    mean_squared_pressure = np.mean(segment_a_weighted**2)\n",
    "    if mean_squared_pressure <= 0:  # Avoid log of zero or negative\n",
    "        continue\n",
    "    leq = 10 * np.log10(mean_squared_pressure / (p0**2))\n",
    "    if np.isfinite(leq):  # Check for valid Leq\n",
    "        leqs.append(leq)\n",
    "\n",
    "# Compute total Leq (logarithmic average)\n",
    "if leqs:\n",
    "    leq_total = 10 * np.log10(np.mean(10**(np.array(leqs)/10)))\n",
    "    print(f\"Total A-weighted Leq: {leq_total:.2f} dB(A)\")\n",
    "else:\n",
    "    print(\"No valid windows processed\")\n",
    "\n",
    "# Optional: Compute Leq for the entire signal using acoustics\n",
    "try:\n",
    "    signal_full = Signal(p, fs=sr)\n",
    "    p_a_weighted = sosfilt(sos, p)\n",
    "    signal_a_weighted = Signal(p_a_weighted, fs=sr)\n",
    "    leq_acoustics = signal_a_weighted.leq()\n",
    "    print(f\"A-weighted Leq (full signal, acoustics): {leq_acoustics:.2f} dB(A)\")\n",
    "except Exception as e:\n",
    "    print(f\"Error computing full-signal Leq: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
